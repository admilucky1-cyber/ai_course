
#82 who is mr.conda???
#83 Tools for Data Science Enviornment

# 1. Data Foundation & Visualization
'''These tools are used for handling, #cleaning, and visualizing dataâ€”the essential first steps of any data project.
Pandas: The industry standard for data manipulation and analysis in Python.
NumPy: Used for high-performance scientific computing and working with multidimensional arrays.
Matplotlib: The core library for creating static, animated, and interactive visualizations.
MySQL: A widely used relational database management system for storing and retrieving data. '''

# 2. Machine Learning & Deep Learning

'''
These frameworks are used to build, train, and deploy AI models.

TensorFlow & Keras: Developed by Google, these are among the most popular frameworks for deep learning and neural networks.

PyTorch: Developed by Meta (Facebook), widely loved by researchers for its flexibility and ease of use.

Scikit-learn (sk-learn): The go-to library for "traditional" machine learning algorithms (like regression, clustering, and decision trees).

Apache Spark: A powerful engine for large-scale data processing (Big Data).

Legacy/Niche Frameworks: Including Theano, Caffe2, CNTK, and Chainer, which were influential in the development of AI but have largely been superseded by PyTorch and TensorFlow.
 '''
# Why these matter
'''Together, these tools form a "tech stack." A typical workflow involves pulling data from MySQL,
cleaning it with Pandas,
visualizing it with Matplotlib,
 and then feeding it into a model built with PyTorch or TensorFlow.'''